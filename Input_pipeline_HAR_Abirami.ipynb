{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Input_pipeline_HAR_Abirami.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uP0rSLyhF8cg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "72c4247c-61e5-4807-c671-906dc3f40010"
      },
      "source": [
        "!pip3 install tensorflow-gpu==2.0.0-beta0\n",
        "#!pip install tensorflow-transform"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.0.0-beta0\n",
            "  Using cached https://files.pythonhosted.org/packages/e8/7e/87c4c94686cda7066f52cbca4c344248516490acdd6b258ec6b8a805d956/tensorflow_gpu-2.0.0b0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (1.14.0.dev2019060501)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (0.2.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (1.17.5)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (3.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (1.0.8)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (0.8.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (1.11.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (1.12.0)\n",
            "Requirement already satisfied: tb-nightly<1.14.0a20190604,>=1.14.0a20190603 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (1.14.0a20190603)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (0.1.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (0.33.6)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0-beta0) (42.0.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0-beta0) (2.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0-beta0) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0-beta0) (0.16.0)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "  Found existing installation: tensorflow-gpu 1.15.0\n",
            "    Uninstalling tensorflow-gpu-1.15.0:\n",
            "      Successfully uninstalled tensorflow-gpu-1.15.0\n",
            "Successfully installed tensorflow-gpu-2.0.0b0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWwy-K4WJYAT",
        "colab_type": "text"
      },
      "source": [
        "Mounting the drive and extracting the HAPT Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0M-6FrhH4dC",
        "colab_type": "code",
        "outputId": "7db0fc5a-52dd-4788-c031-b7247d5a94b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount ('/content/gdrive' )\n",
        "root_path = '/content/gdrive/My Drive/Dataset/HAPT Data Set/'\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvwyerE1MSb6",
        "colab_type": "text"
      },
      "source": [
        "Importing of the packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfCbi3CSMK2m",
        "colab_type": "code",
        "outputId": "6ae355db-1969-478d-b98b-4804e9bea150",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "import pathlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHvGa5yrIsmW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_acc_filename(expID, userID):\n",
        "  if expID <= 9:\n",
        "    filename = \"/acc_exp0\"+ str(expID)\n",
        "  else:\n",
        "    filename = \"/acc_exp\"+ str(expID)\n",
        "  if userID <= 9:\n",
        "    filename = filename + \"_user0\"+str(userID)+ \".txt\"\n",
        "  else:\n",
        "    filename = filename + \"_user\"+str(userID)+ \".txt\"\n",
        "  return filename\n",
        "\n",
        "def generate_gyro_filename(expID, userID):\n",
        "  if expID <= 9:\n",
        "    filename = \"/gyro_exp0\"+ str(expID)\n",
        "  else:\n",
        "    filename = \"/gyro_exp\"+ str(expID)\n",
        "  if userID <= 9:\n",
        "    filename = filename + \"_user0\"+str(userID)+ \".txt\"\n",
        "  else:\n",
        "    filename = filename + \"_user\"+str(userID)+ \".txt\"\n",
        "  return filename"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPhDDR7yvLYt",
        "colab_type": "code",
        "outputId": "98bd0736-cc44-4d93-fe6d-7598a2a55962",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#Defining the path location\n",
        "training_dataset_path = root_path + \"/Training\"\n",
        "testing_dataset_path = root_path + \"/Test\"\n",
        "validation_dataset_path = root_path + \"/Validation\"\n",
        "labels = pathlib.Path(root_path + \"/labels.txt\")\n",
        "print(\"Path of the labels file:\",labels)\n",
        "\n",
        "lables_array = np.loadtxt(fname = labels)\n",
        "print(\"The first row in the labels array\",lables_array[0])\n",
        "print(\"Shape of the labels:\", lables_array.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Path of the labels file: /content/gdrive/My Drive/Dataset/HAPT Data Set/labels.txt\n",
            "The first row in the labels array [1.000e+00 1.000e+00 5.000e+00 2.500e+02 1.232e+03]\n",
            "Shape of the labels: (1214, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYLIWGrSKpYQ",
        "colab_type": "text"
      },
      "source": [
        "Set the location of the root, training, test and validation datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDkCkpclKoi0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_input_array(filepath, StartLimit, EndLimit):\n",
        "  input_array = np.empty((0, 7))\n",
        "  for x in lables_array:\n",
        "    expID = int(x[0])\n",
        "    userID = int(x[1])\n",
        "    label = int(x[2])\n",
        "    start_time = int(x[3])\n",
        "    End_time = int(x[4])\n",
        "    if userID >= StartLimit and userID <= EndLimit:\n",
        "      accpath = pathlib.Path(filepath+generate_acc_filename(expID, userID))\n",
        "      #print(accpath)\n",
        "      features_acc = (np.loadtxt(fname = accpath))[start_time-1:End_time]\n",
        "      #print(features_acc.shape)\n",
        "      gyropath = pathlib.Path(filepath+generate_gyro_filename(expID, userID))\n",
        "      #print(gyropath)\n",
        "      features_gyro = (np.loadtxt(fname = gyropath))[start_time-1:End_time]     \n",
        "      #print(features_gyro.shape)\n",
        "      rows,columns = features_gyro.shape\n",
        "      features = np.hstack((features_acc, features_gyro))\n",
        "      #print(\"Total Features:\", features.shape)\n",
        "      labels = np.full((rows,1),label)\n",
        "      #print(\"labels:\", labels.shape)\n",
        "      features_labels = np.hstack((features,labels))\n",
        "      #print(\"Features with lables:\",features_labels.shape )\n",
        "      #print(type(features_labels))\n",
        "      #print(features_labels)\n",
        "      input_array = np.append(input_array, features_labels, axis = 0)\n",
        "      #print(type(features_labels))\n",
        "      #print(features_labels)\n",
        "  return input_array[:,[0,5]],input_array[:,[6]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzLKnAuqvKZp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_feature, train_label = prepare_input_array(training_dataset_path, 1, 21)\n",
        "validation_feature, validation_label = prepare_input_array(validation_dataset_path, 28, 30)\n",
        "test_feature, test_label = prepare_input_array(testing_dataset_path, 22, 27)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwYJLvHavJfK",
        "colab_type": "code",
        "outputId": "592b4a06-66b1-49c4-dec3-561463a8a7e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "print(train_feature.shape, train_label.shape)\n",
        "print(validation_feature.shape, validation_label.shape)\n",
        "print(test_feature.shape, test_label.shape)\n",
        "print(test_feature)\n",
        "print(test_label)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(554294, 2) (554294, 1)\n",
            "(86018, 2) (86018, 1)\n",
            "(175302, 2) (175302, 1)\n",
            "[[1.01111115 0.01985312]\n",
            " [1.0194445  0.04764749]\n",
            " [1.02916675 0.05131268]\n",
            " ...\n",
            " [1.05277781 0.18753563]\n",
            " [1.36388891 0.20097467]\n",
            " [1.45416669 0.22510384]]\n",
            "[[5.]\n",
            " [5.]\n",
            " [5.]\n",
            " ...\n",
            " [2.]\n",
            " [2.]\n",
            " [2.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgNOdm2xZD1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''def normalization(input_arr):\n",
        "  for x in range(6):\n",
        "    feature_column = input_array[:x]\n",
        "    normalized_feature_column = tft.scale_to_z_score(feature_column)\n",
        "    print(normalized_feature_column)\n",
        "normalization(test_array)'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjNI4p9b4h5-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "48f5a269-88c6-490a-ea27-9e21272a28e7"
      },
      "source": [
        "#creating tensorflow dataset objects\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((train_feature,train_label))\n",
        "validation_ds = tf.data.Dataset.from_tensor_slices((validation_feature,validation_label))\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((test_feature,test_label))\n",
        "\n",
        "print(train_ds)\n",
        "#windowing and batching\n",
        "train_ds = train_ds.window(250,125)\n",
        "validation_ds = validation_ds.window(250,125)\n",
        "test_ds = test_ds.window(250,125)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<TensorSliceDataset shapes: ((2,), (1,)), types: (tf.float64, tf.float64)>\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}